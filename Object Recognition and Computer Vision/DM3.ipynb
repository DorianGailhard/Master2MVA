{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#data.py\nimport zipfile\nimport os\n\nimport torchvision.transforms as transforms\n\n# once the images are loaded, how do we pre-process them before being passed into the network\n# by default, we resize the images to 64 x 64 in size\n# and normalize them to mean = 0 and standard-deviation = 1 based on statistics collected from\n# the training set\ndata_transforms = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n])","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-19T00:23:57.798252Z","iopub.execute_input":"2022-11-19T00:23:57.798688Z","iopub.status.idle":"2022-11-19T00:23:58.096560Z","shell.execute_reply.started":"2022-11-19T00:23:57.798652Z","shell.execute_reply":"2022-11-19T00:23:58.095345Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#model.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nnclasses = 20 \n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv3 = nn.Conv2d(20, 20, kernel_size=5)\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, nclasses)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)","metadata":{"execution":{"iopub.status.busy":"2022-11-19T00:23:59.585793Z","iopub.execute_input":"2022-11-19T00:23:59.586200Z","iopub.status.idle":"2022-11-19T00:23:59.597055Z","shell.execute_reply.started":"2022-11-19T00:23:59.586169Z","shell.execute_reply":"2022-11-19T00:23:59.595896Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#main.py\nimport argparse\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets\nfrom torch.autograd import Variable\nfrom tqdm import tqdm\n\n# Training settings\nparser = argparse.ArgumentParser(description='RecVis A3 training script')\nparser.add_argument('--data', type=str, default='../input/mva-recvis-2022/bird_dataset', metavar='D',\n                    help=\"folder where data is located. train_images/ and val_images/ need to be found in the folder\")\nparser.add_argument('--batch-size', type=int, default=64, metavar='B',\n                    help='input batch size for training (default: 64)')\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\n                    help='number of epochs to train (default: 10)')\nparser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n                    help='learning rate (default: 0.01)')\nparser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n                    help='SGD momentum (default: 0.5)')\nparser.add_argument('--seed', type=int, default=1, metavar='S',\n                    help='random seed (default: 1)')\nparser.add_argument('--log-interval', type=int, default=10, metavar='N',\n                    help='how many batches to wait before logging training status')\nparser.add_argument('--experiment', type=str, default='experiment', metavar='E',\n                    help='folder where experiment outputs are located.')\nargs = parser.parse_args(args=[])\nuse_cuda = torch.cuda.is_available()\ntorch.manual_seed(args.seed)\n\n# Create experiment folder\nif not os.path.isdir(args.experiment):\n    os.makedirs(args.experiment)\n\n# Data initialization and loading\n#from data import data_transforms\n\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder(args.data + '/train_images',\n                         transform=data_transforms),\n    batch_size=args.batch_size, shuffle=True, num_workers=1)\nval_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder(args.data + '/val_images',\n                         transform=data_transforms),\n    batch_size=args.batch_size, shuffle=False, num_workers=1)\n\n# Neural network and optimizer\n# We define neural net in model.py so that it can be reused by the evaluate.py script\n#from model import Net\nmodel = Net()\nif use_cuda:\n    print('Using GPU')\n    model.cuda()\nelse:\n    print('Using CPU')\n\noptimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data.item()))\n\ndef validation():\n    model.eval()\n    validation_loss = 0\n    correct = 0\n    for data, target in val_loader:\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        output = model(data)\n        # sum up batch loss\n        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n        validation_loss += criterion(output, target).data.item()\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    validation_loss /= len(val_loader.dataset)\n    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n        validation_loss, correct, len(val_loader.dataset),\n        100. * correct / len(val_loader.dataset)))\n\n\nfor epoch in range(1, args.epochs + 1):\n    train(epoch)\n    validation()\n    model_file = args.experiment + '/model_' + str(epoch) + '.pth'\n    torch.save(model.state_dict(), model_file)\n    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')","metadata":{"execution":{"iopub.status.busy":"2022-11-19T00:24:02.045056Z","iopub.execute_input":"2022-11-19T00:24:02.045483Z","iopub.status.idle":"2022-11-19T00:24:48.556110Z","shell.execute_reply.started":"2022-11-19T00:24:02.045447Z","shell.execute_reply":"2022-11-19T00:24:48.554441Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Using CPU\nTrain Epoch: 1 [0/462 (0%)]\tLoss: 3.012528\n\nValidation set: Average loss: 0.0651, Accuracy: 5/38 (13%)\nSaved model to experiment/model_1.pth. You can run `python evaluate.py --model experiment/model_1.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 2 [0/462 (0%)]\tLoss: 2.767426\n\nValidation set: Average loss: 0.0679, Accuracy: 1/38 (3%)\nSaved model to experiment/model_2.pth. You can run `python evaluate.py --model experiment/model_2.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 3 [0/462 (0%)]\tLoss: 2.546986\n\nValidation set: Average loss: 0.0650, Accuracy: 6/38 (16%)\nSaved model to experiment/model_3.pth. You can run `python evaluate.py --model experiment/model_3.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 4 [0/462 (0%)]\tLoss: 2.444701\n\nValidation set: Average loss: 0.0661, Accuracy: 3/38 (8%)\nSaved model to experiment/model_4.pth. You can run `python evaluate.py --model experiment/model_4.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 5 [0/462 (0%)]\tLoss: 2.699908\n\nValidation set: Average loss: 0.0627, Accuracy: 5/38 (13%)\nSaved model to experiment/model_5.pth. You can run `python evaluate.py --model experiment/model_5.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 6 [0/462 (0%)]\tLoss: 2.322408\n\nValidation set: Average loss: 0.0717, Accuracy: 3/38 (8%)\nSaved model to experiment/model_6.pth. You can run `python evaluate.py --model experiment/model_6.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 7 [0/462 (0%)]\tLoss: 2.425609\n\nValidation set: Average loss: 0.0604, Accuracy: 6/38 (16%)\nSaved model to experiment/model_7.pth. You can run `python evaluate.py --model experiment/model_7.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 8 [0/462 (0%)]\tLoss: 2.245923\n\nValidation set: Average loss: 0.0631, Accuracy: 3/38 (8%)\nSaved model to experiment/model_8.pth. You can run `python evaluate.py --model experiment/model_8.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 9 [0/462 (0%)]\tLoss: 1.918703\n\nValidation set: Average loss: 0.0700, Accuracy: 4/38 (11%)\nSaved model to experiment/model_9.pth. You can run `python evaluate.py --model experiment/model_9.pth` to generate the Kaggle formatted csv file\n\nTrain Epoch: 10 [0/462 (0%)]\tLoss: 2.306493\n\nValidation set: Average loss: 0.0882, Accuracy: 5/38 (13%)\nSaved model to experiment/model_10.pth. You can run `python evaluate.py --model experiment/model_10.pth` to generate the Kaggle formatted csv file\n\n","output_type":"stream"}]},{"cell_type":"code","source":"#evaluate.py\nimport argparse\nfrom tqdm import tqdm\nimport os\nimport PIL.Image as Image\n\nimport torch\n\n#from model import Net\n\nparser = argparse.ArgumentParser(description='RecVis A3 evaluation script')\nparser.add_argument('--data', type=str, default='../input/mva-recvis-2022/bird_dataset', metavar='D',\n                    help=\"folder where data is located. test_images/ need to be found in the folder\")\nparser.add_argument('--model', type=str, default='./experiment/model_10.pth', metavar='M',\n                    help=\"the model file to be evaluated. Usually it is of the form model_X.pth\")\nparser.add_argument('--outfile', type=str, default='experiment/kaggle.csv', metavar='D',\n                    help=\"name of the output csv file\")\n\nargs = parser.parse_args(args=[])\nuse_cuda = torch.cuda.is_available()\n\nstate_dict = torch.load(args.model)\nmodel = Net()\nmodel.load_state_dict(state_dict)\nmodel.eval()\nif use_cuda:\n    print('Using GPU')\n    model.cuda()\nelse:\n    print('Using CPU')\n\n#from data import data_transforms\n\ntest_dir = args.data + '/test_images/mistery_category'\n\ndef pil_loader(path):\n    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n    with open(path, 'rb') as f:\n        with Image.open(f) as img:\n            return img.convert('RGB')\n\n\noutput_file = open(args.outfile, \"w\")\noutput_file.write(\"Id,Category\\n\")\nfor f in tqdm(os.listdir(test_dir)):\n    if 'jpg' in f:\n        data = data_transforms(pil_loader(test_dir + '/' + f))\n        data = data.view(1, data.size(0), data.size(1), data.size(2))\n        if use_cuda:\n            data = data.cuda()\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1]\n        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n\noutput_file.close()\n\nprint(\"Succesfully wrote \" + args.outfile + ', you can upload this file to the kaggle competition website')","metadata":{"execution":{"iopub.status.busy":"2022-11-19T00:31:51.756795Z","iopub.execute_input":"2022-11-19T00:31:51.757279Z","iopub.status.idle":"2022-11-19T00:32:00.161043Z","shell.execute_reply.started":"2022-11-19T00:31:51.757243Z","shell.execute_reply":"2022-11-19T00:32:00.159932Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Using CPU\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 517/517 [00:08<00:00, 62.79it/s]","output_type":"stream"},{"name":"stdout","text":"Succesfully wrote experiment/kaggle.csv, you can upload this file to the kaggle competition website\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}